{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Part 3.3 - Sentiment Analysis - Recurrent Neural Networks - With Stanford's Glove Embedding.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bala-codes/Sentiment_Analysis_on_Amazon_Product_Reviews_Using_Machine_and_Deep_Learning/blob/master/codes%20(DL%20-%20RNN%20%26%20LSTM)/Part-2.1%20Sentiment%20Analysis%20-%20Training%20-%20Long%20Short%20Term%20Memory%20(LSTM)%20With%20Stanford's%20Glove%20Embedding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IA6kJcUyGCOT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "8d016c6d-7e84-4147-b413-f55528ddca35"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZvAdGgJGDeH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        },
        "outputId": "d7204e90-84a0-45a8-9852-185641961657"
      },
      "source": [
        "#Importing the libraries which are required.\n",
        "import pandas as pd\n",
        "import string\n",
        "import pickle\n",
        "import warnings\n",
        "import numpy as np\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
        "import tensorflow as tf\n",
        "try:\n",
        "    from tensorflow.python.util import module_wrapper as deprecation\n",
        "except ImportError:\n",
        "    from tensorflow.python.util import deprecation_wrapper as deprecation\n",
        "deprecation._PER_MODULE_WARNING_LIMIT = 0\n",
        "\n",
        "from tensorflow.python.util import deprecation\n",
        "deprecation._PRINT_DEPRECATION_WARNINGS = False"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1K8lcgQGSCG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "4086be8b-0547-4d78-aa56-978124d52355"
      },
      "source": [
        "final_df = pd.read_csv('/content/drive/My Drive/Machine Learning Projects/SENTIMENT ANALYSIS - AMAZON CUSTOMER REVIEWS/SOURCE CODES AND DATASETS/Amazon EWS - Final Dataset/finaldf_forlstm.csv') \n",
        "final_df = pd.DataFrame(final_df)\n",
        "\n",
        "final_df.dropna(inplace=True)\n",
        "final_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>review_body_cleaned</th>\n",
              "      <th>star_rating_enc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>GOOD VALUE</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Excellent quality</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>season using it  only fill with water and imme...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Nice bag  Should another strap bottom somethin...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Gave my son used we backpacking  loves it</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ... star_rating_enc\n",
              "0           0  ...             1.0\n",
              "1           1  ...             1.0\n",
              "2           2  ...             1.0\n",
              "3           3  ...             1.0\n",
              "4           4  ...             1.0\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQUTxxnFGVtT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final_df['review_body_cleaned'] = final_df['review_body_cleaned'].astype(str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4nDzVUBGYur",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "93bb5275-13c6-4388-9a1f-923814d449e6"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "sentences = final_df['review_body_cleaned'].values\n",
        "y = final_df['star_rating_enc'].values\n",
        "\n",
        "sentences_train, sentences_test, y_train, y_test = train_test_split(sentences, y, test_size=0.20, random_state=123, shuffle=True)\n",
        "print(sentences_train.shape, sentences_test.shape)\n",
        "print(y_train.shape, y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(318595,) (79649,)\n",
            "(318595,) (79649,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDZ2kvlY5Vi8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "2ea4133a-9753-478f-abbf-42cfc6ef5eb2"
      },
      "source": [
        "ytest1 = list(y_test)\n",
        "print(\"1's\",ytest1.count(1))\n",
        "print(\"0's\",ytest1.count(0))\n",
        "print(\"Thus Test dataset is well Balanced\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1's 39697\n",
            "0's 39952\n",
            "Thus Test dataset is well Balanced\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIaUV3g9QFI-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "73521472-1811-4ed7-c28d-6f3a2e390805"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(sentences_train)\n",
        "\n",
        "X_train = tokenizer.texts_to_sequences(sentences_train)\n",
        "X_test = tokenizer.texts_to_sequences(sentences_test)\n",
        "\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "print(\"Total Vocabulary Size\", vocab_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Total Vocabulary Size 70763\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJNCGdl7QGK7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer.word_index.items()\n",
        "with open('/content/drive/My Drive/Machine Learning Projects/SENTIMENT ANALYSIS - AMAZON CUSTOMER REVIEWS/SOURCE CODES AND DATASETS/PACKAGE 3 -SOURCE CODES AND FILES/Pretrained Models/Deep Learning Models - With Glove Embedding/tokenizer.pkl', 'wb') as handle:\n",
        "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHl2fychQKCb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "maxlen = 300\n",
        "\n",
        "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
        "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3tgAzoBQYZL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "def plot_history(history):\n",
        "    acc = history.history['acc']\n",
        "    val_acc = history.history['val_acc']\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "    x = range(1, len(acc) + 1)\n",
        "    print(\"X\",x)\n",
        "\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(x, acc, 'b', label='Training acc')\n",
        "    plt.plot(x, val_acc, 'r', label='Validation acc')\n",
        "    plt.title('Training and validation accuracy')\n",
        "    plt.legend()\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(x, loss, 'b', label='Training loss')\n",
        "    plt.plot(x, val_loss, 'r', label='Validation loss')\n",
        "    plt.title('Training and validation loss')\n",
        "    plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5oMcbljJc-3",
        "colab_type": "text"
      },
      "source": [
        "# Stanford's Glove Representational Embedding Layer Insertion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Qc_kgL9Jh3K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "outputId": "7c747297-9b69-4e31-f1e1-f115c0ea8b16"
      },
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-11-12 06:14:40--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2019-11-12 06:14:41--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2019-11-12 06:14:41--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  2.10MB/s    in 6m 28s  \n",
            "\n",
            "2019-11-12 06:21:09 (2.12 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qytCTxhoJmIC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "4ed19da4-1d73-416e-bd2b-9309eee7605a"
      },
      "source": [
        "!unzip '/content/glove.6B.zip' -d '/content/Glove_Embedding/'\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/glove.6B.zip\n",
            "  inflating: /content/Glove_Embedding/glove.6B.50d.txt  \n",
            "  inflating: /content/Glove_Embedding/glove.6B.100d.txt  \n",
            "  inflating: /content/Glove_Embedding/glove.6B.200d.txt  \n",
            "  inflating: /content/Glove_Embedding/glove.6B.300d.txt  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-R1Zq6KhLkZJ",
        "colab_type": "text"
      },
      "source": [
        "#GLOVE HERE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELsNpmPqLnnv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "537bf48c-fdf5-4b94-a67a-848867fd0e27"
      },
      "source": [
        "# load the whole embedding into memory\n",
        "\n",
        "embeddings_index = dict()\n",
        "embedding_dims = []\n",
        "\n",
        "#f = open('/content/drive/My Drive/Machine Learning Projects/SENTIMENT ANALYSIS - AMAZON CUSTOMER REVIEWS/SOURCE CODES AND DATASETS/PACKAGE 3 -SOURCE CODES AND FILES/Pretrained Models/Deep Learning Models - With Glove Embedding/glove.6B.100d.txt')\n",
        "\n",
        "embedding_dims = input(print(\"Enter the Embedding Dimensions 50 or 100 or 200 or 300 : \"))\n",
        "\n",
        "f = open('/content/Glove_Embedding/glove.6B.{}d.txt'.format(embedding_dims))\n",
        "for line in f:\n",
        "  values = line.split()\n",
        "  word = values[0]\n",
        "  coefs = np.asarray(values[1:], dtype='float32')\n",
        "  embeddings_index[word] = coefs\n",
        "f.close()\n",
        "\n",
        "print('Loaded %s word vectors.' % len(embeddings_index))\n",
        "\n",
        "################################################################################\n",
        "\n",
        "# create a weight matrix for words in training docs\n",
        "embedding_matrix = np.zeros((vocab_size, 100))\n",
        "for word, i in tokenizer.word_index.items():\n",
        "  embedding_vector = embeddings_index.get(word)\n",
        "  if embedding_vector is not None:\n",
        "    embedding_matrix[i] = embedding_vector\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter the Embedding Dimensions 50 or 100 or 200 or 300 : \n",
            "None100\n",
            "Loaded 400000 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dh7Ad06GG5bb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "f97c51cb-6f1a-479b-a47f-b27e9d7a6591"
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, GRU, Dropout, LSTM, GlobalMaxPooling1D\n",
        "from keras.callbacks import *\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, output_dim = int(embedding_dims) , weights=[embedding_matrix], input_length=maxlen, trainable=False))\n",
        "model.add(LSTM(units = 196, recurrent_dropout = 0.4, dropout=0.4))  # return_sequences = True\n",
        "# model.add(GlobalMaxPooling1D())\n",
        "model.add(Dense(32,activation=\"relu\"))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1,activation=\"sigmoid\"))\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\",metrics=[\"accuracy\"])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_6 (Embedding)      (None, 300, 100)          7076300   \n",
            "_________________________________________________________________\n",
            "lstm_5 (LSTM)                (None, 196)               232848    \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 32)                6304      \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 7,315,485\n",
            "Trainable params: 239,185\n",
            "Non-trainable params: 7,076,300\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3uOmCDyNnCNc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mc = ModelCheckpoint('/content/drive/My Drive/Machine Learning Projects/SENTIMENT ANALYSIS - AMAZON CUSTOMER REVIEWS/SOURCE CODES AND DATASETS/PACKAGE 3 -SOURCE CODES AND FILES/Pretrained Models/Deep Learning Models - With Glove Embedding/SA_LSTM_GLOVE{}.h5'.format(embedding_dims), monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "es = EarlyStopping(monitor='val_loss', patience=4)\n",
        "red_lr= ReduceLROnPlateau(monitor='val_loss',patience=2,verbose=2,factor=0.001,min_delta=0.01)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Jv_jtwkHdiC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "7ccf2fa1-510f-4c90-b4bd-bd6523dcf1a6"
      },
      "source": [
        "%%time\n",
        "history = model.fit(X_train, y_train, epochs=10 , verbose= 2, validation_data=(X_test, y_test), callbacks=[mc,es,red_lr])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 318595 samples, validate on 79649 samples\n",
            "Epoch 1/10\n",
            " - 6439s - loss: 0.6934 - acc: 0.5005 - val_loss: 0.6930 - val_acc: 0.5024\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.50243, saving model to /content/drive/My Drive/Machine Learning Projects/SENTIMENT ANALYSIS - AMAZON CUSTOMER REVIEWS/SOURCE CODES AND DATASETS/PACKAGE 3 -SOURCE CODES AND FILES/Pretrained Models/Deep Learning Models - With Glove Embedding/SA_LSTM_GLOVE100.h5\n",
            "Epoch 2/10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WM_Xfu4h6wov",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "loss, accuracy = model.evaluate(X_train, y_train, verbose=False)\n",
        "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=False)\n",
        "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))\n",
        "\n",
        "plot_history(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwzKPskjH10M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('/content/drive/My Drive/Machine Learning Projects/SENTIMENT ANALYSIS - AMAZON CUSTOMER REVIEWS/SOURCE CODES AND DATASETS/PACKAGE 3 -SOURCE CODES AND FILES/Pretrained Models/Deep Learning Models/sentiment_LSTM_GLOVE_Model.h5')\n",
        "print(\"Model Saved Successfully\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90iBFEiHHV1p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}